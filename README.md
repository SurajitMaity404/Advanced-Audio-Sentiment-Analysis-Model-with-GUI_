# Advanced-Audio-Sentiment-Analysis-Model-with-GUI_
# ğŸ§ Advanced Audio Emotion Recognition Model

This project is a **deep learning-based Audio Sentiment Analysis system** built with **PyTorch**, capable of detecting **8 emotions** from speech audio.  
It can train on custom datasets, analyze uploaded audio files, and even perform **real-time emotion detection** through a microphone (locally via PyAudio).

---

## ğŸ”¥ Features

- ğŸ™ï¸ Detects **8 emotions**: `Happy`, `Sad`, `Angry`, `Neutral`, `Calm`, `Fearful`, `Disgust`, `Surprised`  
- âš¡ Fast **CNN architecture** using Mel-Spectrograms  
- ğŸ“‚ Train on your **own dataset** or uploaded audio files  
- ğŸ”Š **Real-time voice emotion detection** via microphone  
- ğŸ§  Built with **PyTorch**, **Librosa**, and **Torchaudio**  
- ğŸš€ Fully runnable in **Google Colab** or **VS Code (local machine)**  

---

## ğŸ§© Model Architecture

The model uses a **Convolutional Neural Network (CNN)** that learns emotional features from mel-spectrograms (frequency vs time representations of audio).  
It captures tone, pitch, and rhythm patterns that distinguish human emotions.

---

## ğŸ› ï¸ Installation

### 1. Clone this repository
```bash
git clone https://github.com/your-username/audio-emotion-recognition.git
cd audio-emotion-recognition
